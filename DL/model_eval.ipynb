{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from dataset_eval import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from visdom import Visdom\n",
    "import copy\n",
    "\n",
    "num_classes = 7\n",
    "batch_size = 32\n",
    "feature_extract = False\n",
    "pretrained = False\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloaders):\n",
    "    model.eval() \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for step, (inputs, labels) in enumerate(dataloaders):\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        # loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "    return running_corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sea', 'green', 'city', 'house_building', 'face', 'house_indoor', 'office']\n",
      "tensor(191, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = '/home/jun/Github/BoVW/dataset/'\n",
    "\n",
    "train_ds = Dataset(BASE_DIR)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = models.vgg11_bn(pretrained=pretrained).cuda()\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "model =  torch.nn.DataParallel(model).cuda()\n",
    "model.load_state_dict(torch.load('./model/net25-0.001.pth'))\n",
    "# model.load_state_dict(torch.load('./model/net_finetune21-0.000.pth'))\n",
    "# model.load_state_dict(torch.load('./model/net_scratch32-0.000.pth'))\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "acc = eval_model(model, train_dl)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_img = cv2.imread(BASE_DIR + 'train/2/1.jpg')\n",
    "# test_img = cv2.resize(test_img, (input_size,input_size), interpolation=cv2.INTER_CUBIC)\n",
    "# test_img = np.moveaxis(test_img,2,0)\n",
    "# test_img = torch.FloatTensor(test_img).cuda().unsqueeze(0)\n",
    "# # print(test_img.shape)\n",
    "\n",
    "# outputs = model(test_img)\n",
    "# print(outputs.shape)\n",
    "# print(outputs)\n",
    "# # loss = loss_fn(outputs, labels)\n",
    "# _, preds = torch.max(outputs, 1)\n",
    "# print(preds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c0765f9bcf74431e05650db67b3f046ba8e213c3b5b9c20db33f6d2ed90b485"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
